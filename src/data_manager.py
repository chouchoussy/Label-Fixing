import pandas as pd
import numpy as np
import torch
from torch.utils.data import TensorDataset, DataLoader

class DataManager:
    """
    Qu·∫£n l√Ω vi·ªác t·∫£i, x·ª≠ l√Ω v√† t·∫°o DataLoader cho d·ªØ li·ªáu.
    H·ªó tr·ª£ c·∫£ nh√£n c·ª©ng ban ƒë·∫ßu v√† nh√£n m·ªÅm trong qu√° tr√¨nh l·∫∑p l·∫°i.
    """
    def __init__(self, ground_truth_path: str, features_path: str, batch_size=64):
        self.ground_truth_path = ground_truth_path
        self.features_path = features_path
        self.batch_size = batch_size
        
        self.embeddings = None
        self.noisy_labels = None
        self.true_labels = None
        self.num_classes = None
        
        self.X_tensor = None
        self.y_noisy_tensor = None # S·∫Ω l√† soft labels (N, C)
        self.y_true_tensor = None

        self._load_and_process_data()
        self._prepare_pytorch_tensors()

    def _load_and_process_data(self):
        """
        T·∫£i, h·ª£p nh·∫•t v√† tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ c√°c ngu·ªìn.
        """
        print("B·∫Øt ƒë·∫ßu qu√° tr√¨nh t·∫£i v√† h·ª£p nh·∫•t d·ªØ li·ªáu...")
        
        df_csv = pd.read_csv(self.ground_truth_path)
        df_csv.rename(columns={'label': 'true_label'}, inplace=True)
        df_feather = pd.read_feather(self.features_path)
        
        df_aligned = pd.concat([df_feather, df_csv[['true_label']]], axis=1)
        print("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c h·ª£p nh·∫•t.")

        self.noisy_labels = df_aligned['label'].values.astype(int)
        self.true_labels = df_aligned['true_label'].values.astype(int)
        
        embedding_df = df_aligned.drop(columns=['label', 'true_label'])
        self.embeddings = embedding_df.values
        
        print(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t d·ªØ li·ªáu th√†nh c√¥ng.")
        print(f"T·ªïng s·ªë m·∫´u x·ª≠ l√Ω: {len(self.embeddings)}")
        print(f"K√≠ch th∆∞·ªõc embedding (s·ªë chi·ªÅu): {self.embeddings.shape[1]}")

    def _prepare_pytorch_tensors(self):
        """
        Chu·∫©n b·ªã d·ªØ li·ªáu v√† chuy·ªÉn nh√£n nhi·ªÖu ban ƒë·∫ßu sang d·∫°ng soft (one-hot).
        """
        if self.num_classes is None:
             self.num_classes = len(np.unique(self.true_labels))
             print(f"S·ªë l∆∞·ª£ng l·ªõp: {self.num_classes}")
        
        self.X_tensor = torch.tensor(self.embeddings, dtype=torch.float32)
        self.y_true_tensor = torch.tensor(self.true_labels, dtype=torch.long)
        
        noisy_labels_one_hot = np.eye(self.num_classes)[self.noisy_labels]
        self.y_noisy_tensor = torch.tensor(noisy_labels_one_hot, dtype=torch.float32)
        print("‚úÖ Nh√£n nhi·ªÖu ban ƒë·∫ßu ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang d·∫°ng soft (one-hot).")

    def update_noisy_soft_labels(self, new_soft_labels: np.ndarray):
        """
        C·∫≠p nh·∫≠t nh√£n nhi·ªÖu b·∫±ng "soft labels" m·ªõi cho v√≤ng l·∫∑p ti·∫øp theo.
        """
        print("\nüîÑ C·∫≠p nh·∫≠t nh√£n m·ªÅm (soft labels) cho v√≤ng l·∫∑p ti·∫øp theo...")
        if new_soft_labels.shape != (len(self.embeddings), self.num_classes):
            raise ValueError(f"Shape c·ªßa nh√£n m·ªÅm kh√¥ng ch√≠nh x√°c! Expecting {(len(self.embeddings), self.num_classes)}, got {new_soft_labels.shape}")
        
        self.y_noisy_tensor = torch.tensor(new_soft_labels, dtype=torch.float32)
        self.noisy_labels = np.argmax(new_soft_labels, axis=1)
        print("‚úÖ Nh√£n m·ªÅm ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.")

    def get_full_dataset(self):
        return TensorDataset(self.X_tensor, self.y_noisy_tensor, self.y_true_tensor)

    def get_full_dataloader(self, shuffle=True):
        dataset = self.get_full_dataset()
        return DataLoader(dataset, batch_size=self.batch_size, shuffle=shuffle, drop_last=True)